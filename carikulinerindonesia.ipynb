{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgNw3Zhq+kuaKjSNMeUPtO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tes-kious/flask/blob/main/carikulinerindonesia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0Dkp5cjH8m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCUhYs-HHlDU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_multiple_pages():\n",
        "    base_url = \"https://www.carikulinerindonesia.com/#barat\"\n",
        "    current_page = 1\n",
        "    all_data = []\n",
        "\n",
        "    while True:\n",
        "        url = f\"{base_url}#{current_page}#\"  # Ubah sesuai dengan URL dan parameter paginasi yang sesuai\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "            # Lakukan pencarian dan ekstraksi data dari tabel menggunakan BeautifulSoup\n",
        "            # Tambahkan data ke dalam all_data\n",
        "\n",
        "            # Contoh ekstraksi data dari tabel dengan class \"data-row\"\n",
        "            data_rows = soup.find_all(\"a\", class_=\"card\")\n",
        "            for row in data_rows:\n",
        "                # Ekstraksi data dari setiap kolom dalam row\n",
        "                # Tambahkan data ke dalam all_data\n",
        "\n",
        "            # Cek apakah ada halaman selanjutnya\n",
        "            next_page = soup.find(\"a\", class_=\"page-item disabled\")\n",
        "            if next_page:\n",
        "                break  # Keluar dari loop jika tidak ada halaman selanjutnya\n",
        "            current_page += 1\n",
        "        else:\n",
        "            print(f\"Failed to fetch data for page {current_page}. Status code: {response.status_code}\")\n",
        "            break\n",
        "\n",
        "    return all_data\n",
        "\n",
        "def main():\n",
        "    scraped_data = scrape_multiple_pages()\n",
        "    if scraped_data:\n",
        "        # Lakukan sesuatu dengan data yang telah di-scrape\n",
        "        print(scraped_data)\n",
        "    else:\n",
        "        print(\"Scraping failed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Otfdt_MnH65R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cloudscraper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_sCbuuQPTbO",
        "outputId": "588405c7-aa33-471d-b1cb-0b1cd10f9282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cloudscraper\n",
            "  Downloading cloudscraper-1.2.71-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.10/dist-packages (from cloudscraper) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from cloudscraper) (2.31.0)\n",
            "Collecting requests-toolbelt>=0.9.1 (from cloudscraper)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper) (2023.7.22)\n",
            "Installing collected packages: requests-toolbelt, cloudscraper\n",
            "Successfully installed cloudscraper-1.2.71 requests-toolbelt-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cloudscraper\n",
        "\n",
        "scraper = cloudscraper.create_scraper()\n"
      ],
      "metadata": {
        "id": "V-Lri73hPXTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "KVQ1c9nlLJG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "id": "v87E3UWmNKEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "3qhD3yzyNFDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_page = soup.find(\"li\", class_=\"page-item disabled\")"
      ],
      "metadata": {
        "id": "lfVgMh6TQKrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_page"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuJE62LoQVo7",
        "outputId": "8b4142d8-b58c-456a-d58a-914543e0f49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<li class=\"page-item disabled\"><a class=\"page-link\" href=\"#\" title=\"Next\">»</a></li>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan pencarian dan ekstraksi data dari tabel menggunakan BeautifulSoup\n",
        "# Tambahkan data ke dalam all_data\n",
        "\n",
        "# Contoh ekstraksi data dari tabel dengan class \"data-row\"\n",
        "card_elements = soup.find_all('div', class_='card')\n",
        "#for row in data_rows:\n",
        "    # Ekstraksi data dari setiap kolom dalam row\n",
        "    # Tambahkan data ke dalam all_data\n",
        "\n",
        "# Cek apakah ada halaman selanjutnya\n"
      ],
      "metadata": {
        "id": "DvTcHqNnQEAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "card_elements"
      ],
      "metadata": {
        "id": "-lbXDZLfV3bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.carikulinerindonesia.com/barat\"\n",
        "current_page = 4084\n",
        "\n",
        "#while True:\n",
        "url = f\"{base_url}/{current_page}/\"  # Ubah sesuai dengan URL dan parameter paginasi yang sesuai\n",
        "response = scraper.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "            card_elements = soup.find_all('div', class_='card')\n"
      ],
      "metadata": {
        "id": "KPQGFJ2KW0bc"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "card_elements[10].find_all('img')[1]['title']\n",
        "#card_elements[10].find('img', align='left').text.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "04Rbo8LBYRLz",
        "outputId": "4111e1f8-2d76-453a-850d-23955508514a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rating 4.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = scraper.get(\"http://www.carikulinerindonesia.com\")\n",
        "if response.status_code == 200:\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "metadata": {
        "id": "fHnaMCdcvXxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div_elements = soup.find_all('ul', class_='navbar-nav ml-auto')"
      ],
      "metadata": {
        "id": "KMK1kAhSvZqz"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36a0EjV011Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div_elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3UtiDzSwpiO",
        "outputId": "5ce20706-bf47-420e-8945-caf04fd1903f"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<ul class=\"navbar-nav ml-auto\"><li class=\"nav-item\"><a class=\"nav-link\" href=\"https://www.carikulinerindonesia.com/menu-rekomendasi/\" style=\"color:#ffffff;font-family: Arial, Helvetica, sans-serif;font-weight:bold;font-size:16px;\" title=\"Rekomendasi\"><i class=\"fas fa-star\"></i> Rekomendasi</a></li><li class=\"nav-item\"><a class=\"nav-link\" href=\"https://www.carikulinerindonesia.com/katalog/\" style=\"color:#ffffff;font-family: Arial, Helvetica, sans-serif;font-weight:bold;font-size:16px;\" title=\"Katalog\"><i class=\"fas fa-book\"></i> Katalog</a></li><li class=\"nav-item\"><a class=\"nav-link\" href=\"https://www.carikulinerindonesia.com/kota/\" style=\"color:#ffffff;font-family: Arial, Helvetica, sans-serif;font-weight:bold;font-size:16px;\" title=\"Kota\"><i class=\"fas fa-city\"></i> Kota</a></li><li class=\"nav-item\"><a class=\"nav-link\" href=\"https://www.carikulinerindonesia.com/brand/\" style=\"color:#ffffff;font-family: Arial, Helvetica, sans-serif;font-weight:bold;font-size:16px;\" title=\"Brand\"><i class=\"fas fa-store\"></i> Brand</a></li><li class=\"nav-item\"><a class=\"nav-link\" href=\"https://resep.carikulinerindonesia.com\" style=\"color:#ffffff;font-family: Arial, Helvetica, sans-serif;font-weight:bold;font-size:16px;\" target=\"_blank\" title=\"Resep\"><i class=\"fas fa-bowl-food\"></i> Resep</a></li><li class=\"nav-item\"><a class=\"nav-link\" href=\"https://www.carikulinerindonesia.com/terbaru/\" style=\"color:#ffffff;font-family: Arial, Helvetica, sans-serif;font-weight:bold;font-size:16px;\" title=\"Data Terbaru\"><i class=\"fas fa-database\"></i> Terbaru</a></li></ul>]"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = div_elements[0].find_all('li', class_='nav-item')"
      ],
      "metadata": {
        "id": "JQVQun4NvocL"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt[1].find('a')['href']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lHQZn1dtyd7h",
        "outputId": "86c43556-ac7c-4005-de16-c0bf13659244"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.carikulinerindonesia.com/katalog/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = scraper.get(\"http://resep.carikulinerindonesia.com\")\n",
        "if response.status_code == 200:\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "metadata": {
        "id": "fgyAFXKfxh2M"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div_elements = soup.find_all('div', style='padding:2px;')"
      ],
      "metadata": {
        "id": "SUpPJEZb2aUU"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div_elements = div_elements.find('a')"
      ],
      "metadata": {
        "id": "S7_h-1xH5BEd"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div_elements[0].find('a')['href']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YZC37Y_A47Aa",
        "outputId": "51d19571-76e0-4147-8926-863dd7718007"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://resep.carikulinerindonesia.com/kategori/ayam/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div_elements[0].find('span', class_='mg-text').text  #.find('a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fwfxwaTh3ZU_",
        "outputId": "9ae84cdf-e7d2-4d0a-ef8b-cd11fb2342b0"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ayam'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n"
      ],
      "metadata": {
        "id": "D8Uw5p5HfDJV"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = scraper.get(\"http://www.carikulinerindonesia.com\")\n",
        "if response.status_code == 200:\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "  div_elements = soup.find_all('div', style='padding:3px;')\n",
        "  current_page = 0\n",
        "  for div in div_elements:\n",
        "      # Mendapatkan atribut href dari elemen\n",
        "      link = div.find('a')['href']\n",
        "\n",
        "      # Mendapatkan teks dari atribut title pada elemen\n",
        "      title = div.find('a')['title']\n",
        "\n",
        "      # Mendapatkan URL gambar dari elemen\n",
        "      img_url = div.find('img')['src']\n",
        "\n",
        "      print('Title:', title)\n",
        "      print('Link:', link)\n",
        "      print('Image URL:', img_url)\n",
        "      print('-' * 20)\n",
        "\n",
        "\n",
        "      base_url = link #\"https://www.carikulinerindonesia.com/barat\"\n",
        "      current_page = 0\n",
        "      while True:\n",
        "        current_page += 1\n",
        "        url = f\"{base_url}{current_page}/\"  # Ubah sesuai dengan URL dan parameter paginasi yang sesuai\n",
        "        response = scraper.get(url)\n",
        "        print(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "            card_elements = soup.find_all('div', class_='card')\n",
        "            for card in card_elements:\n",
        "              try :\n",
        "                  print(\"loop : \" , current_page)\n",
        "                  print(\"data : \" , card)\n",
        "                  # Mendapatkan atribut href dari elemen\n",
        "                  link = card.find('a')['href']\n",
        "\n",
        "                  # Mendapatkan teks dari atribut title pada elemen\n",
        "                  title = card.find('a')['title']\n",
        "\n",
        "                  # Mendapatkan URL gambar dari elemen\n",
        "                  img_url = card.find('img')['src']\n",
        "                  price = card.find('h3', class_='card-title').text.strip()\n",
        "                  address = card.find('h3', style='color:#555151;font-size:13px;white-space:nowrap;text-overflow:ellipsis;overflow:hidden;').text.strip()\n",
        "\n",
        "                  rating = card_elements[10].find_all('img')[1]['title']\n",
        "\n",
        "                  print('Title:', title)\n",
        "                  print('Link:', link)\n",
        "                  print('Image URL:', img_url)\n",
        "                  print('Price:', price)\n",
        "                  print('Address:', address)\n",
        "                  print('Rating:', rating)\n",
        "                  print('-' * 200)\n",
        "\n",
        "                  #if (current_page == 2) :\n",
        "                  #next_page = soup.find(\"li\", class_=\"page-item disabled\")\n",
        "                  #if next_page:\n",
        "                  #    break  # Keluar dari loop jika tidak ada halaman selanjutnya\n",
        "                  #current_page += 1\n",
        "              except Exception as e:\n",
        "              # Handle exceptions, such as network errors or parsing issues\n",
        "                print(\"An error occurred:\", e)\n",
        "        time.sleep(3)\n",
        "        if (current_page == 1) :\n",
        "            break  # Keluar dari loop jika tidak ada halaman selanjutnya"
      ],
      "metadata": {
        "id": "Qnvf8-0OX2Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gS7rulOFVqsu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}